{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fde2f2f7-e499-462b-b645-4554478ac157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional\n",
    "import random\n",
    "import datetime, os\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3d08015-7ca6-4a71-a692-b8819a7a37e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.1369e-16, -2.2027e-16, -2.5224e-16, -2.1316e-17,  4.3077e-17,\n",
      "         4.0901e-16,  9.9476e-17, -6.0396e-17], dtype=torch.float64) tensor([1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000],\n",
      "       dtype=torch.float64)\n",
      "tensor([0.3540, 0.6460], dtype=torch.float64) tensor([0.4787, 0.4787], dtype=torch.float64)\n",
      "torch.Size([500, 8])\n"
     ]
    }
   ],
   "source": [
    "%run Dataset_Loading.ipynb\n",
    "%run Model_Loading.ipynb\n",
    "%run S_Rprop.ipynb\n",
    "%run S_Rprop_V2.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "766e0551-084d-4716-8b4e-db44bb7f979b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1c4a916-29c1-4cde-aafb-41a1ca6c5086",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mandersoren\u001b[0m (\u001b[33msorenandersenbachelorthesis\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4f6008f-d53a-408d-b870-95d13f59f018",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"MNIST\"\n",
    "network = \"Standard_no_D\"\n",
    "optim_mthd = \"S-RpropV2\"\n",
    "minibatches = True  \n",
    "n_epochs = 5\n",
    "learning_rate = 5e-3\n",
    "batch_size_train = [600]   #300 still needs 3 runs + delete latest run 3 in WandB\n",
    "#lr_batch_sizes = [50, 100, 200, 500, 1000, 2500, 5000, 10000, 20000, 30000, 60000]\n",
    "lr_batch_sizes = [3000, 6000, 15000]\n",
    "eta_m, eta_p = 0.5, 1.2   \n",
    "min_lr, max_lr = 1e-10, 1e-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09305c47-753a-4365-805c-7b1813c8fa1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e54eebe2d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 3\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "885ae684-6e69-428e-90fa-5de87aa15cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_counter = []\n",
    "lr_updates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "314ac028-b582-4937-b228-32eb5ef575c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 3000 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_205501-9zk0tc8f</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/9zk0tc8f/workspace' target=\"_blank\">Run 4</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/9zk0tc8f/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/9zk0tc8f/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soren\\AppData\\Local\\Temp\\ipykernel_12244\\1195817258.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.077485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\soren\\AppData\\Local\\Temp\\ipykernel_12244\\1195817258.py:15: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return F.log_softmax(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.602040\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.186208\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.852628\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.596999\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.530070\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.379118\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.342087\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.261661\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.220252\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.211076\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.187439\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.144955\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.147502\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.134711\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.113394\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.135987\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.110224\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.099448\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.108190\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.091334\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.088255\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.086450\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.090258\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.092371\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.070163\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.087691\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.078161\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.079363\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.087994\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.071611\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.072736\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.077678\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.066484\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.070630\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.075269\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.084872\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.086365\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.091393\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.072972\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.076975\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.062919\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.076400\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.067750\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.056036\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.074482\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.089248\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.063272\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.082844\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.057689\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.066936\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.064173\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.073487\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.069044\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.061890\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.072001\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.066689\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.056258\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.070548\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.079180\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.072296\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.064568\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.078358\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.074578\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.074688\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.073472\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.058759\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.079064\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.067984\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.051951\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.052216\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.056122\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.067065\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.069873\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.080898\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.050313\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.059671\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.062085\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.081484\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.074811\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.071326\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.067638\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.081358\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.068531\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.064261\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.072892\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.070077\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.055020\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.072006\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.061264\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.087508\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.048987\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.061520\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.075671\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.060362\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.065618\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.068692\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.060898\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.061357\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.068703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.0687</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 4</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/9zk0tc8f/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/9zk0tc8f/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_205501-9zk0tc8f\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 3000 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38ef3d55ede549cbba50e80d3f6ef872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_205735-0coqzd53</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/0coqzd53/workspace' target=\"_blank\">Run 5</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/0coqzd53/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/0coqzd53/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.194631\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.616567\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.130495\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.835317\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.639201\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.539125\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.332603\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.344204\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.236592\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.197676\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.169921\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.168574\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.158780\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.140419\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.121781\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.120420\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.095521\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.109888\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.094599\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.084389\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.091077\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.086022\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.084124\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.077649\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.085814\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.086938\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.080353\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.066051\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.071563\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.078907\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.073231\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.073498\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.081905\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.081614\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.070689\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.071645\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.075328\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.073716\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.067245\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.063559\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.063955\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.067775\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.074960\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.069883\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.075820\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.084663\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.071088\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.077134\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.053318\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.057957\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.055869\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.053771\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.061199\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.063870\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.062240\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.057776\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.071919\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.062280\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.060047\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.062094\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.059709\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.084266\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.056204\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.062477\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.057780\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.062264\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.063241\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.070827\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.048879\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.063614\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.065346\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.065766\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.082050\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.054883\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.065099\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.066868\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.061082\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.061732\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.056074\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.060931\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.069446\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.064697\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.061041\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.065074\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.060922\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.068670\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.060577\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.067045\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.070173\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.058319\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.065335\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.055637\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.061737\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.053656\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.050982\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.071084\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.060882\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.064068\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.056427\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.076277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.05884447156952497, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.07628</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 5</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/0coqzd53/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/0coqzd53/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_205735-0coqzd53\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 3000 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f9f38b8d4a4340be6a44689412eb6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01127777777777131, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_210006-twjcmuzt</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/twjcmuzt/workspace' target=\"_blank\">Run 6</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/twjcmuzt/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/twjcmuzt/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.170401\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.633800\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.223563\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.838435\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.615589\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.529180\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.401303\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.342437\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.240224\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.196430\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.214925\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.179528\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.164814\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.150975\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.151045\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.116892\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.110805\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.103855\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.113805\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.107833\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.093245\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.100859\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.080806\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.085149\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.081255\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.080764\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.067621\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.067743\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.080908\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.071838\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.066970\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.069194\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.077952\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.061275\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.067574\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.067924\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.065355\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.070844\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.067968\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.068647\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.064643\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.063370\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.076911\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.075165\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.081039\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.052846\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.059121\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.050182\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.071924\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.053590\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.067197\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.053717\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.065664\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.060887\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.054002\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.055860\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.063615\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.065356\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.055935\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.054394\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.051317\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.066244\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.062613\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.062143\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.054044\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.068755\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.068010\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.070390\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.063686\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.067353\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.057529\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.060176\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.062090\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.058877\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.057093\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.045596\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.062106\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.051876\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.060499\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.055483\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.052070\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.064056\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.052835\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.068489\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.053856\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.064346\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.064045\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.059794\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.064646\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.061911\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.060429\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.054701\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.049964\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.069743\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.051233\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.057967\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.055498\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.057833\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.072368\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.061684\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.06168</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 6</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/twjcmuzt/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/twjcmuzt/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_210006-twjcmuzt\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 3000 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59a7f33a3c8542eea74bc26917c846bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01127777777777131, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_210237-dteh0oya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/dteh0oya/workspace' target=\"_blank\">Run 7</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/dteh0oya/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/dteh0oya/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.148480\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.606849\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.255148\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.884340\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.702717\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.452153\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.411776\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.353291\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.269303\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.229412\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.220607\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.174647\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.154188\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.134919\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.117877\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.138676\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.115817\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.101070\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.102187\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.108719\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.106130\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.083780\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.090604\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.080024\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.103231\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.077252\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.076342\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.067632\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.084854\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.075004\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.088007\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.082341\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.079098\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.068327\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.065262\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.076433\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.085086\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.068754\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.069429\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.065123\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.063424\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.059622\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.071715\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.056621\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.063302\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.069780\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.066183\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.074318\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.070447\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.062514\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.063440\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.072494\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.066678\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.060681\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.059086\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.071923\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.064726\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.081572\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.062496\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.074075\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.070545\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.062419\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.060377\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.053929\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.069807\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.071523\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.077095\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.057457\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.063409\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.088675\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.058382\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.083858\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.055867\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.068518\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.054583\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.074437\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.067703\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.058483\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.041365\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.055835\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.064932\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.061607\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.063644\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.061382\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.077791\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.069461\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.062426\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.057880\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.061168\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.066454\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.064457\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.068790\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.072047\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.052473\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.062987\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.058465\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.060440\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.066290\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.062688\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.065890\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.06589</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 7</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/dteh0oya/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/dteh0oya/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_210237-dteh0oya\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 3000 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3486299c68c44dbd8d7536208bee412c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01127777777777131, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_210508-ns5ngyzs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ns5ngyzs/workspace' target=\"_blank\">Run 8</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ns5ngyzs/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ns5ngyzs/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.109371\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.564590\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.184635\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 1.030178\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.715615\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.487050\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.406457\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.326396\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.284379\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.222761\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.220640\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.191520\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.168541\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.153294\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.140687\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.125728\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.133416\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.114695\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.113603\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.096318\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.115866\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.088468\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.084348\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.091831\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.095850\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.078771\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.076243\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.094925\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.082649\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.080872\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.066514\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.065051\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.068666\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.067611\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.076755\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.069489\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.083496\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.081375\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.073820\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.069899\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.066290\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.071790\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.058303\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.072390\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.077817\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.066162\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.072516\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.070973\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.060948\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.079003\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.076700\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.069919\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.070738\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.066495\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.067481\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.068925\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.056089\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.069512\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.064956\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.061142\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.074344\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.059387\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.073886\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.057534\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.064057\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.064117\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.059870\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.060705\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.077295\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.081959\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.066004\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.068961\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.063397\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.062071\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.067585\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.067343\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.057546\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.058414\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.065041\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.077229\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.058604\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.069521\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.069947\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.063943\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.061515\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.054670\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.076870\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.063847\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.069027\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.053057\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.061889\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.068958\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.058971\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.070596\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.064823\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.078063\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.068625\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.066426\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.068893\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.069114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.05884447156952497, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.06911</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 8</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ns5ngyzs/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ns5ngyzs/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_210508-ns5ngyzs\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 6000 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafef401e17e4a2594a49ed0c921b098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_210748-pz4f8fkg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz4f8fkg/workspace' target=\"_blank\">Run 4</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz4f8fkg/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz4f8fkg/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.144152\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.548446\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.321595\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 1.074860\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.882000\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.720835\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.641142\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.563426\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.516286\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.424005\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.403984\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.396932\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.350647\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.315791\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.277133\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.248568\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.240212\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.248018\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.222005\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.184536\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.184915\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.158043\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.168631\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.146746\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.134343\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.126010\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.133296\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.113113\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.100009\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.113401\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.089090\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.099775\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.095906\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.079578\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.078747\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.088016\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.078424\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.078979\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.078516\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.059932\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.059156\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.060656\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.060017\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.061883\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.049666\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.055154\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.074212\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.041306\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.066467\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.039679\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.044446\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.043964\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.053114\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.043074\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.045440\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.051453\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.046666\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.030431\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.049177\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.053840\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.033860\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.027928\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.044560\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.036339\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.040099\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.045095\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.024036\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.040548\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.035171\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.027797\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.027589\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.022976\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.029728\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.039955\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.038638\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.019877\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.023936\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.031965\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.058313\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.037766\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.032505\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.016989\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.033545\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.032246\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.026415\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.027701\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.035963\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.020240\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.030196\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.027712\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.037206\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.015234\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.021539\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.032524\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.018520\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.023875\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.026026\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.023811\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.033885\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.036705\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.03671</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 4</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz4f8fkg/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz4f8fkg/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_210748-pz4f8fkg\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 6000 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7c2df4fc7749159558dd57058823ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888925108, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_211020-79bjpfvo</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/79bjpfvo/workspace' target=\"_blank\">Run 5</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/79bjpfvo/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/79bjpfvo/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.194631\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.616567\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.193609\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.934635\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.839128\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.732373\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.592009\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.579776\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.467077\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.403242\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.379057\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.368142\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.307161\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.261206\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.233260\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.244029\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.228286\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.206058\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.185707\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.185765\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.168024\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.140059\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.146610\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.136514\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.121898\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.138903\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.120516\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.103209\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.096218\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.114569\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.096890\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.094168\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.088632\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.095670\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.070034\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.077204\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.068567\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.083701\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.075024\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.057954\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.052853\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.065694\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.056805\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.056882\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.066674\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.058936\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.051398\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.061625\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.041872\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.049052\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.045501\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.034782\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.045216\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.050433\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.056205\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.035045\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.051590\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.045893\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.040815\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.047145\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.034201\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.045615\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.028274\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.034613\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.032074\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.033926\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.029577\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.034749\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.026806\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.037273\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.027385\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.030266\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.047985\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.025694\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.034449\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.037550\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.036707\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.038895\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.021429\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.031469\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.029587\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.031942\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.024167\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.032371\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.021236\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.026954\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.023794\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.027751\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.035749\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.026675\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.022718\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.029395\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.029359\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.024096\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.014944\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.029397\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.033544\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.029549\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.030040\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.037443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.05841699036472784, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.03744</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 5</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/79bjpfvo/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/79bjpfvo/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_211020-79bjpfvo\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 6000 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc2ea5070ad7469a8e96062b9b1ecfdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01127777777777131, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_211251-hrjs7e86</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/hrjs7e86/workspace' target=\"_blank\">Run 6</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/hrjs7e86/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/hrjs7e86/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.170401\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.633800\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.215945\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.926262\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.817547\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.669612\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.607343\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.552029\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.422700\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.378162\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.381482\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.380390\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.316482\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.293302\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.296702\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.260899\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.197001\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.198023\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.215398\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.191410\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.177221\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.169600\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.142348\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.153572\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.139207\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.119783\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.097700\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.096940\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.112053\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.097229\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.086478\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.103622\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.099541\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.071369\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.081228\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.063037\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.075900\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.099565\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.065973\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.066075\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.054925\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.068425\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.068340\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.059814\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.065819\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.045548\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.048917\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.040244\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.057461\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.049942\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.044533\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.038701\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.046920\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.047838\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.037547\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.036088\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.038934\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.050720\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.038159\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.045376\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.029458\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.040665\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.035432\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.053746\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.027782\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.041623\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.031901\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.043715\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.036711\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.040609\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.027573\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.033778\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.038776\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.025900\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.034482\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.023655\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.028635\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.029450\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.031688\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.027338\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.021185\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.030629\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.024283\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.028632\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.029098\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.029373\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.029938\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.029284\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.038517\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.028578\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.023334\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.022099\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.023675\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.041882\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.026086\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.026789\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.025079\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.028349\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.026424\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.026985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.05889233585922799, max=1.…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.02698</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 6</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/hrjs7e86/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/hrjs7e86/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_211251-hrjs7e86\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 6000 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41bbb375e0f7453fa58b7b697d00a9c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888884685, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_211522-pz6jju7g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz6jju7g/workspace' target=\"_blank\">Run 7</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz6jju7g/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz6jju7g/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.148480\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.606849\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.266881\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.966465\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.788895\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.706811\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.589414\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.530819\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.467697\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.408972\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.373473\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.334409\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.317140\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.253577\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.229113\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.249554\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.215093\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.203584\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.207116\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.205870\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.188218\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.167422\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.151288\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.146920\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.157813\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.148687\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.121985\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.113413\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.124316\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.115612\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.112058\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.108685\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.097329\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.096117\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.078568\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.089085\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.104305\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.078459\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.074802\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.073621\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.057404\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.069148\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.073080\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.058814\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.054692\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.057894\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.066266\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.078759\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.061236\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.059270\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.058239\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.059183\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.055701\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.048282\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.049375\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.053639\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.055976\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.063487\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.051097\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.058013\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.053141\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.036189\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.036413\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.028080\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.040237\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.050296\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.046632\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.030001\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.044560\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.049647\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.036430\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.045455\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.041937\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.042409\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.033318\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.038378\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.040521\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.037758\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.024772\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.028617\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.024696\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.031100\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.038617\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.027334\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.038259\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.029392\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.034769\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.026414\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.027403\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.028248\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.030107\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.034127\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.041494\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.022584\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.031094\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.024188\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.022352\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.036802\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.024658\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.036246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▃▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.03625</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 7</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz6jju7g/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/pz6jju7g/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_211522-pz6jju7g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 6000 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46131aa21a07495babc0cb3000409430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_211755-34yfluk6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/34yfluk6/workspace' target=\"_blank\">Run 8</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/34yfluk6/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/34yfluk6/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.109371\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.564590\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.291598\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 1.127427\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.907316\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.819730\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.665085\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.689002\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.517922\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.441765\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.445649\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.388435\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.348836\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.299421\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.303009\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.278833\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.267999\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.228182\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.199968\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.197284\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.210702\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.183526\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.178870\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.183455\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.160932\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.145289\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.129228\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.156576\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.135208\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.126919\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.121324\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.104706\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.100882\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.079266\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.084126\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.089764\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.108279\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.099920\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.095194\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.086560\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.066319\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.070785\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.067618\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.085988\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.068098\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.057005\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.067753\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.064560\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.052767\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.067700\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.051723\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.060068\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.059767\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.059552\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.046406\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.043458\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.041044\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.047046\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.050015\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.044482\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.042887\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.036461\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.034448\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.034188\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.032653\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.037152\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.031612\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.042126\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.037239\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.039390\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.034581\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.038590\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.037661\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.033976\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.040203\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.045400\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.025526\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.029720\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.029809\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.039917\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.023021\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.025084\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.026517\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.028736\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.029035\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.030220\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.033729\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.020525\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.031052\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.022854\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.019761\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.034071\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.026018\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.023273\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.019052\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.039376\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.029147\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.034167\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.021314\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.028731\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▄▃▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.02873</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 8</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/34yfluk6/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/34yfluk6/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_211755-34yfluk6\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 15000 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7539dd5df324759ab02313dacf40e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011288888888884685, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_212029-zxne82e5</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/zxne82e5/workspace' target=\"_blank\">Run 4</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/zxne82e5/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/zxne82e5/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.144152\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.548446\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.321595\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 1.074860\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.835958\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.697644\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.642224\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.554959\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.491499\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.498047\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.518122\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.389437\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.354950\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.307925\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.288551\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.242889\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.237308\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.232185\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.224313\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.198211\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.174789\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.142086\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.163990\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.146570\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.135865\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.133058\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.116873\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.118260\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.114992\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.115585\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.091505\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.079593\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.093255\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.073734\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.084066\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.076771\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.075352\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.072383\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.091251\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.067829\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.059655\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.059207\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.063396\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.063359\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.049228\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.051507\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.076321\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.045632\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.064696\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.050063\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.037478\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.043661\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.053583\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.049353\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.040023\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.063965\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.048535\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.026972\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.051281\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.060462\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.036539\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.034193\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.047917\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.043702\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.050805\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.049734\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.029546\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.046733\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.041683\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.032949\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.030360\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.027271\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.034094\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.036058\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.037223\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.021650\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.024516\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.038441\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.060526\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.037803\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.033287\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.020292\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.037716\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.032315\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.032996\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.031409\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.030923\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.021743\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.036849\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.024699\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.038624\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.019767\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.029674\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.031624\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.023453\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.032510\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.031067\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.025675\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.038734\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.040444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.04044</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 4</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/zxne82e5/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/zxne82e5/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_212029-zxne82e5\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 15000 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1036d67dd408423fb9ef1dcea9446fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.01127777777777131, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_212308-d3jyuxmn</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/d3jyuxmn/workspace' target=\"_blank\">Run 5</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/d3jyuxmn/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/d3jyuxmn/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.194631\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.616567\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.193609\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.934635\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.780986\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.718643\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.583885\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.544508\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.456586\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.403219\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.401951\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.343615\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.347212\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.305813\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.260343\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.242286\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.199566\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.202536\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.182540\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.169698\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.156788\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.180832\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.148367\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.126531\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.128084\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.133426\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.118811\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.104404\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.106498\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.112772\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.097856\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.095659\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.098627\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.090412\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.079684\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.069206\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.075414\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.077031\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.073530\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.057664\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.058883\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.063519\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.053668\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.059109\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.067355\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.062698\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.053120\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.055200\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.044647\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.046948\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.047732\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.042087\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.048493\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.056823\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.050284\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.037662\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.052136\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.043091\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.043980\n",
      "Train Epoch: 3 [60000/60000 (99%)]\tLoss: 0.046811\n",
      "Train Epoch: 4 [3000/60000 (4%)]\tLoss: 0.039521\n",
      "Train Epoch: 4 [6000/60000 (9%)]\tLoss: 0.041193\n",
      "Train Epoch: 4 [9000/60000 (14%)]\tLoss: 0.032610\n",
      "Train Epoch: 4 [12000/60000 (19%)]\tLoss: 0.038096\n",
      "Train Epoch: 4 [15000/60000 (24%)]\tLoss: 0.032724\n",
      "Train Epoch: 4 [18000/60000 (29%)]\tLoss: 0.032115\n",
      "Train Epoch: 4 [21000/60000 (34%)]\tLoss: 0.036376\n",
      "Train Epoch: 4 [24000/60000 (39%)]\tLoss: 0.034312\n",
      "Train Epoch: 4 [27000/60000 (44%)]\tLoss: 0.025712\n",
      "Train Epoch: 4 [30000/60000 (49%)]\tLoss: 0.038024\n",
      "Train Epoch: 4 [33000/60000 (54%)]\tLoss: 0.033553\n",
      "Train Epoch: 4 [36000/60000 (59%)]\tLoss: 0.036387\n",
      "Train Epoch: 4 [39000/60000 (64%)]\tLoss: 0.055607\n",
      "Train Epoch: 4 [42000/60000 (69%)]\tLoss: 0.031002\n",
      "Train Epoch: 4 [45000/60000 (74%)]\tLoss: 0.039055\n",
      "Train Epoch: 4 [48000/60000 (79%)]\tLoss: 0.041372\n",
      "Train Epoch: 4 [51000/60000 (84%)]\tLoss: 0.034872\n",
      "Train Epoch: 4 [54000/60000 (89%)]\tLoss: 0.043152\n",
      "Train Epoch: 4 [57000/60000 (94%)]\tLoss: 0.024011\n",
      "Train Epoch: 4 [60000/60000 (99%)]\tLoss: 0.034939\n",
      "Train Epoch: 5 [3000/60000 (4%)]\tLoss: 0.030662\n",
      "Train Epoch: 5 [6000/60000 (9%)]\tLoss: 0.028240\n",
      "Train Epoch: 5 [9000/60000 (14%)]\tLoss: 0.026548\n",
      "Train Epoch: 5 [12000/60000 (19%)]\tLoss: 0.033922\n",
      "Train Epoch: 5 [15000/60000 (24%)]\tLoss: 0.023610\n",
      "Train Epoch: 5 [18000/60000 (29%)]\tLoss: 0.029734\n",
      "Train Epoch: 5 [21000/60000 (34%)]\tLoss: 0.029148\n",
      "Train Epoch: 5 [24000/60000 (39%)]\tLoss: 0.033702\n",
      "Train Epoch: 5 [27000/60000 (44%)]\tLoss: 0.038293\n",
      "Train Epoch: 5 [30000/60000 (49%)]\tLoss: 0.023153\n",
      "Train Epoch: 5 [33000/60000 (54%)]\tLoss: 0.024582\n",
      "Train Epoch: 5 [36000/60000 (59%)]\tLoss: 0.031808\n",
      "Train Epoch: 5 [39000/60000 (64%)]\tLoss: 0.026741\n",
      "Train Epoch: 5 [42000/60000 (69%)]\tLoss: 0.028650\n",
      "Train Epoch: 5 [45000/60000 (74%)]\tLoss: 0.023117\n",
      "Train Epoch: 5 [48000/60000 (79%)]\tLoss: 0.033097\n",
      "Train Epoch: 5 [51000/60000 (84%)]\tLoss: 0.027845\n",
      "Train Epoch: 5 [54000/60000 (89%)]\tLoss: 0.030224\n",
      "Train Epoch: 5 [57000/60000 (94%)]\tLoss: 0.027862\n",
      "Train Epoch: 5 [60000/60000 (99%)]\tLoss: 0.036881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>█▅▃▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Loss over latest 3000 patterns</td><td>0.03688</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">Run 5</strong> at: <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/d3jyuxmn/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/d3jyuxmn/workspace</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20240515_212308-d3jyuxmn\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 15000 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83bf9142d9b94ad2bf39fabd9b83deee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\soren\\OneDrive\\Python Projects\\RPROP & SGD\\wandb\\run-20240515_212541-ldrqwsbv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ldrqwsbv/workspace' target=\"_blank\">Run 6</a></strong> to <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ldrqwsbv/workspace' target=\"_blank\">https://wandb.ai/sorenandersenbachelorthesis/MNIST/runs/ldrqwsbv/workspace</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3000/60000 (4%)]\tLoss: 2.170401\n",
      "Train Epoch: 1 [6000/60000 (9%)]\tLoss: 1.633800\n",
      "Train Epoch: 1 [9000/60000 (14%)]\tLoss: 1.215945\n",
      "Train Epoch: 1 [12000/60000 (19%)]\tLoss: 0.926262\n",
      "Train Epoch: 1 [15000/60000 (24%)]\tLoss: 0.835298\n",
      "Train Epoch: 1 [18000/60000 (29%)]\tLoss: 0.674795\n",
      "Train Epoch: 1 [21000/60000 (34%)]\tLoss: 0.561561\n",
      "Train Epoch: 1 [24000/60000 (39%)]\tLoss: 0.532436\n",
      "Train Epoch: 1 [27000/60000 (44%)]\tLoss: 0.429350\n",
      "Train Epoch: 1 [30000/60000 (49%)]\tLoss: 0.395631\n",
      "Train Epoch: 1 [33000/60000 (54%)]\tLoss: 0.415930\n",
      "Train Epoch: 1 [36000/60000 (59%)]\tLoss: 0.357044\n",
      "Train Epoch: 1 [39000/60000 (64%)]\tLoss: 0.338559\n",
      "Train Epoch: 1 [42000/60000 (69%)]\tLoss: 0.308918\n",
      "Train Epoch: 1 [45000/60000 (74%)]\tLoss: 0.299522\n",
      "Train Epoch: 1 [48000/60000 (79%)]\tLoss: 0.236399\n",
      "Train Epoch: 1 [51000/60000 (84%)]\tLoss: 0.203934\n",
      "Train Epoch: 1 [54000/60000 (89%)]\tLoss: 0.199642\n",
      "Train Epoch: 1 [57000/60000 (94%)]\tLoss: 0.219628\n",
      "Train Epoch: 1 [60000/60000 (99%)]\tLoss: 0.203392\n",
      "Train Epoch: 2 [3000/60000 (4%)]\tLoss: 0.170232\n",
      "Train Epoch: 2 [6000/60000 (9%)]\tLoss: 0.167748\n",
      "Train Epoch: 2 [9000/60000 (14%)]\tLoss: 0.125807\n",
      "Train Epoch: 2 [12000/60000 (19%)]\tLoss: 0.144517\n",
      "Train Epoch: 2 [15000/60000 (24%)]\tLoss: 0.145874\n",
      "Train Epoch: 2 [18000/60000 (29%)]\tLoss: 0.116567\n",
      "Train Epoch: 2 [21000/60000 (34%)]\tLoss: 0.099168\n",
      "Train Epoch: 2 [24000/60000 (39%)]\tLoss: 0.119178\n",
      "Train Epoch: 2 [27000/60000 (44%)]\tLoss: 0.108422\n",
      "Train Epoch: 2 [30000/60000 (49%)]\tLoss: 0.083686\n",
      "Train Epoch: 2 [33000/60000 (54%)]\tLoss: 0.084500\n",
      "Train Epoch: 2 [36000/60000 (59%)]\tLoss: 0.094847\n",
      "Train Epoch: 2 [39000/60000 (64%)]\tLoss: 0.095039\n",
      "Train Epoch: 2 [42000/60000 (69%)]\tLoss: 0.059360\n",
      "Train Epoch: 2 [45000/60000 (74%)]\tLoss: 0.086184\n",
      "Train Epoch: 2 [48000/60000 (79%)]\tLoss: 0.073737\n",
      "Train Epoch: 2 [51000/60000 (84%)]\tLoss: 0.067499\n",
      "Train Epoch: 2 [54000/60000 (89%)]\tLoss: 0.095367\n",
      "Train Epoch: 2 [57000/60000 (94%)]\tLoss: 0.068974\n",
      "Train Epoch: 2 [60000/60000 (99%)]\tLoss: 0.082506\n",
      "Train Epoch: 3 [3000/60000 (4%)]\tLoss: 0.057028\n",
      "Train Epoch: 3 [6000/60000 (9%)]\tLoss: 0.059080\n",
      "Train Epoch: 3 [9000/60000 (14%)]\tLoss: 0.072745\n",
      "Train Epoch: 3 [12000/60000 (19%)]\tLoss: 0.065792\n",
      "Train Epoch: 3 [15000/60000 (24%)]\tLoss: 0.070140\n",
      "Train Epoch: 3 [18000/60000 (29%)]\tLoss: 0.044173\n",
      "Train Epoch: 3 [21000/60000 (34%)]\tLoss: 0.048544\n",
      "Train Epoch: 3 [24000/60000 (39%)]\tLoss: 0.038335\n",
      "Train Epoch: 3 [27000/60000 (44%)]\tLoss: 0.068212\n",
      "Train Epoch: 3 [30000/60000 (49%)]\tLoss: 0.050534\n",
      "Train Epoch: 3 [33000/60000 (54%)]\tLoss: 0.050225\n",
      "Train Epoch: 3 [36000/60000 (59%)]\tLoss: 0.042694\n",
      "Train Epoch: 3 [39000/60000 (64%)]\tLoss: 0.051411\n",
      "Train Epoch: 3 [42000/60000 (69%)]\tLoss: 0.041430\n",
      "Train Epoch: 3 [45000/60000 (74%)]\tLoss: 0.044474\n",
      "Train Epoch: 3 [48000/60000 (79%)]\tLoss: 0.034205\n",
      "Train Epoch: 3 [51000/60000 (84%)]\tLoss: 0.043311\n",
      "Train Epoch: 3 [54000/60000 (89%)]\tLoss: 0.056585\n",
      "Train Epoch: 3 [57000/60000 (94%)]\tLoss: 0.045194\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 68\u001b[0m\n\u001b[0;32m     65\u001b[0m     wandb_loss \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3000\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(data))\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Epoch: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m [\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m (\u001b[39m\u001b[38;5;132;01m{:.0f}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)]\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, (batch_idx\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(data),\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28mlen\u001b[39m(train_loader\u001b[38;5;241m.\u001b[39mdataset), \u001b[38;5;241m100.\u001b[39m \u001b[38;5;241m*\u001b[39m batch_idx \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loader), wandb_loss\u001b[38;5;241m.\u001b[39mitem()))\n\u001b[1;32m---> 68\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mLoss over latest 3000 patterns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mwandb_loss\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     69\u001b[0m training_loss\u001b[38;5;241m.\u001b[39mappend(wandb_loss)\n\u001b[0;32m     70\u001b[0m wandb_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:420\u001b[0m, in \u001b[0;36m_run_decorator._noop.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    417\u001b[0m         wandb\u001b[38;5;241m.\u001b[39mtermwarn(message, repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    418\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39mDummy()\n\u001b[1;32m--> 420\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:371\u001b[0m, in \u001b[0;36m_run_decorator._noop_on_finish.<locals>.decorator_fn.<locals>.wrapper_fn\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    368\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m: Type[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun\u001b[39m\u001b[38;5;124m\"\u001b[39m], \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_is_finished\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 371\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    373\u001b[0m     default_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    374\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) is finished. The call to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be ignored. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    375\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease make sure that you are using an active run.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    376\u001b[0m     )\n\u001b[0;32m    377\u001b[0m     resolved_message \u001b[38;5;241m=\u001b[39m message \u001b[38;5;129;01mor\u001b[39;00m default_message\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:361\u001b[0m, in \u001b[0;36m_run_decorator._attach.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attaching \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1838\u001b[0m, in \u001b[0;36mRun.log\u001b[1;34m(self, data, step, commit, sync)\u001b[0m\n\u001b[0;32m   1831\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_settings\u001b[38;5;241m.\u001b[39m_shared \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1832\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mtermwarn(\n\u001b[0;32m   1833\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn shared mode, the use of `wandb.log` with the step argument is not supported \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1834\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand will be ignored. Please refer to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mwburls\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwandb_define_metric\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1835\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon how to customize your x-axis.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1836\u001b[0m         repeat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1837\u001b[0m     )\n\u001b[1;32m-> 1838\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1602\u001b[0m, in \u001b[0;36mRun._log\u001b[1;34m(self, data, step, commit)\u001b[0m\n\u001b[0;32m   1599\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys()):\n\u001b[0;32m   1600\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mKey values passed to `wandb.log` must be strings.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1602\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_partial_history_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1604\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1605\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mgetpid() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_pid \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_attached:\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py:1474\u001b[0m, in \u001b[0;36mRun._partial_history_callback\u001b[1;34m(self, row, step, commit)\u001b[0m\n\u001b[0;32m   1471\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39minterface:\n\u001b[0;32m   1472\u001b[0m     not_using_tensorboard \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(wandb\u001b[38;5;241m.\u001b[39mpatched[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtensorboard\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_partial_history\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1476\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1478\u001b[0m \u001b[43m        \u001b[49m\u001b[43mflush\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcommit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1479\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpublish_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnot_using_tensorboard\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1480\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:590\u001b[0m, in \u001b[0;36mInterfaceBase.publish_partial_history\u001b[1;34m(self, data, user_step, step, flush, publish_step, run)\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m flush \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    589\u001b[0m     partial_history\u001b[38;5;241m.\u001b[39maction\u001b[38;5;241m.\u001b[39mflush \u001b[38;5;241m=\u001b[39m flush\n\u001b[1;32m--> 590\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_partial_history\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpartial_history\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:89\u001b[0m, in \u001b[0;36mInterfaceShared._publish_partial_history\u001b[1;34m(self, partial_history)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_partial_history\u001b[39m(\n\u001b[0;32m     86\u001b[0m     \u001b[38;5;28mself\u001b[39m, partial_history: pb\u001b[38;5;241m.\u001b[39mPartialHistoryRequest\n\u001b[0;32m     87\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(partial_history\u001b[38;5;241m=\u001b[39mpartial_history)\n\u001b[1;32m---> 89\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in callback <bound method _WandbInit._pause_backend of <wandb.sdk.wandb_init._WandbInit object at 0x000001E560294EB0>> (for post_run_cell):\n"
     ]
    },
    {
     "ename": "ConnectionResetError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectionResetError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_init.py:439\u001b[0m, in \u001b[0;36m_WandbInit._pause_backend\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbackend\u001b[38;5;241m.\u001b[39minterface \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpausing backend\u001b[39m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m--> 439\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterface\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py:670\u001b[0m, in \u001b[0;36mInterfaceBase.publish_pause\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpublish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    669\u001b[0m     pause \u001b[38;5;241m=\u001b[39m pb\u001b[38;5;241m.\u001b[39mPauseRequest()\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish_pause\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpause\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py:357\u001b[0m, in \u001b[0;36mInterfaceShared._publish_pause\u001b[1;34m(self, pause)\u001b[0m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish_pause\u001b[39m(\u001b[38;5;28mself\u001b[39m, pause: pb\u001b[38;5;241m.\u001b[39mPauseRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    356\u001b[0m     rec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_request(pause\u001b[38;5;241m=\u001b[39mpause)\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrec\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py:51\u001b[0m, in \u001b[0;36mInterfaceSock._publish\u001b[1;34m(self, record, local)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_publish\u001b[39m(\u001b[38;5;28mself\u001b[39m, record: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpb.Record\u001b[39m\u001b[38;5;124m\"\u001b[39m, local: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign(record)\n\u001b[1;32m---> 51\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_record_publish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:221\u001b[0m, in \u001b[0;36mSockClient.send_record_publish\u001b[1;34m(self, record)\u001b[0m\n\u001b[0;32m    219\u001b[0m server_req \u001b[38;5;241m=\u001b[39m spb\u001b[38;5;241m.\u001b[39mServerRequest()\n\u001b[0;32m    220\u001b[0m server_req\u001b[38;5;241m.\u001b[39mrecord_publish\u001b[38;5;241m.\u001b[39mCopyFrom(record)\n\u001b[1;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mserver_req\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:155\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:152\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[1;34m(self, msg)\u001b[0m\n\u001b[0;32m    150\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py:130\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    128\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[0;32m    129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 130\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    131\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[0;32m    132\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mConnectionResetError\u001b[0m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread ChkStopThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\threading.py\", line 953, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 286, in check_stop_status\n",
      "    self._loop_check_status(\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 224, in _loop_check_status\n",
      "    local_handle = request()\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 828, in deliver_stop_status\n",
      "    return self._deliver_stop_status(status)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 494, in _deliver_stop_status\n",
      "    return self._deliver_record(record)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 459, in _deliver_record\n",
      "Exception in thread IntMsgThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "Exception in thread NetStatThr:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\threading.py\", line 1016, in _bootstrap_inner\n",
      "    handle = mailbox._deliver_record(record, interface=self)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 455, in _deliver_record\n",
      "    self.run()\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\threading.py\", line 953, in run\n",
      "    self.run()\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\threading.py\", line 953, in run\n",
      "        interface._publish(record)self._target(*self._args, **self._kwargs)\n",
      "    \n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "self._target(*self._args, **self._kwargs)  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 300, in check_internal_messages\n",
      "\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 268, in check_network_status\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self._loop_check_status(\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 224, in _loop_check_status\n",
      "    self._loop_check_status(\n",
      "      File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\wandb_run.py\", line 224, in _loop_check_status\n",
      "self.send_server_request(server_req)    \n",
      "local_handle = request()  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "\n",
      "      File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 836, in deliver_network_status\n",
      "local_handle = request()\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface.py\", line 844, in deliver_internal_messages\n",
      "        self._send_message(msg)return self._deliver_network_status(status)\n",
      "\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "      File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 510, in _deliver_network_status\n",
      "return self._deliver_internal_messages(internal_message)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 516, in _deliver_internal_messages\n",
      "        self._sendall_with_error_handle(header + data)return self._deliver_record(record)\n",
      "\n",
      "      File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 459, in _deliver_record\n",
      "return self._deliver_record(record)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_shared.py\", line 459, in _deliver_record\n",
      "    sent = self._sock.send(data)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "        handle = mailbox._deliver_record(record, interface=self)handle = mailbox._deliver_record(record, interface=self)\n",
      "\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 455, in _deliver_record\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\mailbox.py\", line 455, in _deliver_record\n",
      "    interface._publish(record)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    interface._publish(record)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\interface\\interface_sock.py\", line 51, in _publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self._sock_client.send_record_publish(record)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 221, in send_record_publish\n",
      "    self.send_server_request(server_req)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "    self.send_server_request(server_req)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 155, in send_server_request\n",
      "    self._send_message(msg)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "    self._send_message(msg)    \n",
      "self._sendall_with_error_handle(header + data)  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 152, in _send_message\n",
      "\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    self._sendall_with_error_handle(header + data)\n",
      "  File \"C:\\Users\\soren\\.conda\\envs\\tf\\lib\\site-packages\\wandb\\sdk\\lib\\sock_client.py\", line 130, in _sendall_with_error_handle\n",
      "    sent = self._sock.send(data)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "    sent = self._sock.send(data)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n"
     ]
    }
   ],
   "source": [
    "plots = []\n",
    "for lr_batch_size in lr_batch_sizes:\n",
    "#for minibatch_size in batch_size_train:\n",
    "    minibatch_size = batch_size_train[0]\n",
    "    lr_debug = 0\n",
    "    if optim_mthd == \"Rprop\":\n",
    "        lr_batch_size = minibatch_size\n",
    "    train_loader = torch.utils.data.DataLoader(torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])), batch_size=minibatch_size, shuffle=True)\n",
    "    for j in range(5):\n",
    "        training_loss = []\n",
    "        print(minibatch_size,lr_batch_size, j)\n",
    "        if network == \"Standard\":\n",
    "            model = Big_Net()\n",
    "        elif network == \"Medium\":\n",
    "            model = Medium_Net()\n",
    "        elif network == \"Standard_no_D\":\n",
    "            model = Big_Net_no_D()\n",
    "        elif network == \"Deep\":\n",
    "            model = Deep_Net()\n",
    "        model.to(device)\n",
    "        if optim_mthd == \"SGD\":\n",
    "            optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "        elif optim_mthd == \"Rprop\":\n",
    "            optimizer = optim.Rprop(model.parameters(), lr=learning_rate, step_sizes=(min_lr, max_lr))\n",
    "        elif optim_mthd == \"S-RpropV0)\":\n",
    "            optimizer = stochastic_adaptive(model.parameters(), lr=learning_rate, etas=(eta_m, eta_p), step_sizes=(min_lr, max_lr))\n",
    "        elif optim_mthd == \"S-Rprop\":\n",
    "            optimizer = SRPROP(model.parameters(), M=minibatch_size, L=lr_batch_size, lr=learning_rate, etas=(eta_m, eta_p), step_sizes=(min_lr, max_lr))\n",
    "        run = wandb.init(project=\"MNIST\",\n",
    "                                     name=f\"Run {j+1+3}\",\n",
    "                                     config={\"epochs\": n_epochs,\n",
    "                                             \"optim_mthd\": optim_mthd,\n",
    "                                             \"learning_rate\": learning_rate,\n",
    "                                             \"dataset\": dataset,\n",
    "                                             #\"h_Layers\": 3,\n",
    "                                             #\"nodes_p_layer\": 32,\n",
    "                                             \"minibatches\": minibatches,\n",
    "                                             \"minibatch_size\": minibatch_size if minibatches else 60000,\n",
    "                                             #\"Dropout_layers\": False,\n",
    "                                             \"lr_batch_size\": lr_batch_size})\n",
    "                                             #\"eta-, eta+\": (eta_m, eta_p),\n",
    "                                             #\"min_lr, max_lr\": (min_lr, max_lr),\n",
    "                                             #\"Re-run\": \"V2\"})\n",
    "         #                                    \"Final\": True})\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            model.train()\n",
    "            wandb_loss = 0\n",
    "            #debug_losses = []\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                data, target = data.to(device), target.to(device)\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = F.nll_loss(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                wandb_loss += loss\n",
    "                if ((batch_idx+1)*len(data))%3000==0:\n",
    "                    if minibatch_size<3000:\n",
    "                        wandb_loss /= (3000/len(data))\n",
    "                    print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, (batch_idx+1) * len(data),\n",
    "                    len(train_loader.dataset), 100. * batch_idx / len(train_loader), wandb_loss.item()))\n",
    "                    wandb.log({\"Loss over latest 3000 patterns\": wandb_loss})\n",
    "                    training_loss.append(wandb_loss)\n",
    "                    wandb_loss = 0\n",
    "            train_loader = Shuffle_MNIST_Data(train_loader, random_seed)\n",
    "        wandb.finish()\n",
    "        plots.append(training_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d89825-22d0-48ef-a515-6de5a6e52eca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
